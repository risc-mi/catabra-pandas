{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame Merging Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare `catabra_pandas.merge_intervals` to [`janitor.conditional_join`](https://github.com/pyjanitor-devs/pyjanitor/tree/dev) and [`polars.join_where`](https://github.com/pola-rs/polars) in terms of time and memory efficiency.\n",
    "\n",
    "The Appendix briefly discusses [`pandas.IntervalIndex`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.IntervalIndex.html#pandas.IntervalIndex)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import janitor\n",
    "import polars as pl\n",
    "import catabra_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import memory_profiler, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our own profiling function, to measure time and memory simultaneously\n",
    "\n",
    "def profile(func, args, kwargs, reps: int = 1, memory: bool = True, print_output: bool = True, size_fun=len):\n",
    "    def _f():\n",
    "        tic = time.time()\n",
    "        for _ in range(reps - 1):\n",
    "            func(*args, **kwargs)\n",
    "        out = func(*args, **kwargs)\n",
    "        return (out, (time.time() - tic) / reps)\n",
    "    \n",
    "    if memory:\n",
    "        baseline = memory_profiler.memory_usage()[0]\n",
    "        max_mem, (retval, t) = memory_profiler.memory_usage((_f, [], {}), retval=True, max_usage=True)\n",
    "        incr = max_mem - baseline\n",
    "    else:\n",
    "        retval, t = _f()\n",
    "        max_mem = incr = 0\n",
    "\n",
    "    if print_output:\n",
    "        print(\"output size:\", size_fun(retval))\n",
    "        if t >= 1.0:\n",
    "            ts = \"{:.2f} s\".format(t)\n",
    "        elif t >= 1e-3:\n",
    "            ts = \"{:.2f} ms\".format(t * 1e3)\n",
    "        else:\n",
    "            ts = \"{:.2f} us\".format(t * 1e6)\n",
    "        print(\"wall time:  \", ts)\n",
    "\n",
    "        if memory:\n",
    "            print(\"peak memory:\", \"{:.2f} MiB\".format(max_mem))\n",
    "            print(\"increment:  \", \"{:.2f} MiB\".format(incr))\n",
    "\n",
    "    return retval, t, max_mem, incr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Equality and Interval-Containment Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_frames(n_groups: int, group_size: int, seed: int = 42) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    rng = np.random.RandomState(seed)\n",
    "\n",
    "    left = pd.DataFrame(\n",
    "        data=dict(\n",
    "            group=rng.randint(0, n_groups, size=n_groups*group_size*10),\n",
    "            start=rng.uniform(-10, 10, size=n_groups*group_size*10)\n",
    "        )\n",
    "    )\n",
    "    left[\"stop\"] = left[\"start\"] + rng.uniform(1, 10, size=len(left))\n",
    "\n",
    "    right = pd.DataFrame(\n",
    "        data=dict(\n",
    "            group=rng.randint(0, n_groups, size=n_groups*group_size),\n",
    "            start=rng.uniform(15, 25, size=n_groups*group_size)\n",
    "        )\n",
    "    )\n",
    "    right[\"stop\"] = right[\"start\"] + rng.uniform(1, 5, size=len(right))\n",
    "\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000000\n",
      "1000000\n"
     ]
    }
   ],
   "source": [
    "left, right = create_random_frames(10_000, 100)\n",
    "print(len(left))\n",
    "print(len(right))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to merge `left` and `right` on column `\"group\"` (equality constraint), and additionally restrict the result to rows where `left[\"start\"] <= right[\"stop\"] <= left[\"stop\"]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with `catabra_pandas.merge_intervals`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size: 1487230\n",
      "wall time:   5.47 s\n",
      "peak memory: 3108.66 MiB\n",
      "increment:   2756.04 MiB\n"
     ]
    }
   ],
   "source": [
    "out, wall, peak, incr = profile(\n",
    "    catabra_pandas.merge_intervals,\n",
    "    [left, right],\n",
    "    dict(on=\"group\", how=\"inner\", left_start=\"start\", left_stop=\"stop\", right_start=\"stop\", right_stop=\"stop\", keep_order=False, copy=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare that to `janitor.conditional_join`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size: 1487230\n",
      "wall time:   31.93 s\n",
      "peak memory: 38761.12 MiB\n",
      "increment:   38350.74 MiB\n"
     ]
    }
   ],
   "source": [
    "out_janitor, wall_janitor, peak_janitor, incr_janitor = profile(\n",
    "    janitor.conditional_join,\n",
    "    [left, right, (\"group\", \"group\", \"==\"), (\"start\", \"stop\", \"<=\"), (\"stop\", \"stop\", \">=\")],\n",
    "    dict(how=\"inner\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**janitor is 5 times slower and requires more than 10 times more intermediate memory!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, what about `pl.join_where`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_pl = pl.from_pandas(left)\n",
    "right_pl = pl.from_pandas(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size: 1487230\n",
      "wall time:   9.91 s\n",
      "peak memory: 50504.18 MiB\n",
      "increment:   49866.89 MiB\n"
     ]
    }
   ],
   "source": [
    "out_pl, wall_pl, peak_pl, incr_pl = profile(\n",
    "    left_pl.join_where,\n",
    "    [right_pl, pl.col(\"group\") == pl.col(\"group_right\"), pl.col(\"start\") <= pl.col(\"stop_right\"), pl.col(\"stop\") >= pl.col(\"stop_right\")],\n",
    "    {}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Polars is 2 times slower and requires almost 20 times more intermediate memory!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Equality and Interval-Overlap Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same example as before, but this time match all rows from `left` and `right` with the same `\"group\"` and overlapping intervals (defined by `\"start\"` and `\"stop\"`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`catabra_pandas.merge_intervals`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size: 11616148\n",
      "wall time:   9.73 s\n",
      "peak memory: 3093.24 MiB\n",
      "increment:   2682.39 MiB\n"
     ]
    }
   ],
   "source": [
    "out, wall, peak, incr = profile(\n",
    "    catabra_pandas.merge_intervals,\n",
    "    [left, right],\n",
    "    dict(on=\"group\", how=\"inner\", left_start=\"start\", left_stop=\"stop\", right_start=\"start\", right_stop=\"stop\", keep_order=False, copy=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`janitor.conditional_join`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size: 11616148\n",
      "wall time:   28.04 s\n",
      "peak memory: 39164.60 MiB\n",
      "increment:   38367.25 MiB\n"
     ]
    }
   ],
   "source": [
    "out_janitor, wall_janitor, peak_janitor, incr_janitor = profile(\n",
    "    janitor.conditional_join,\n",
    "    [left, right, (\"group\", \"group\", \"==\"), (\"start\", \"stop\", \"<=\"), (\"stop\", \"start\", \">=\")],\n",
    "    dict(how=\"inner\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**janitor is still 3 times slower and requires more than 10 times more intermediate memory!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pl.join_where`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size: 11616148\n",
      "wall time:   9.34 s\n",
      "peak memory: 50786.97 MiB\n",
      "increment:   49362.09 MiB\n"
     ]
    }
   ],
   "source": [
    "out_pl, wall_pl, peak_pl, incr_pl = profile(\n",
    "    left_pl.join_where,\n",
    "    [right_pl, pl.col(\"group\") == pl.col(\"group_right\"), pl.col(\"start\") <= pl.col(\"stop_right\"), pl.col(\"stop\") >= pl.col(\"start_right\")],\n",
    "    {}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Polars is on-par in terms of computation time, but still requires almost 20 times more intermediate memory!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Single Inequality Constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is taken from [Polars' test suite](https://github.com/pola-rs/polars/blob/main/py-polars/tests/benchmark/test_join_where.py). The goal is to join two DataFrames based on a single inequality constraint and no equality constraints.\n",
    "\n",
    "This use-case is covered by `catabra_pandas.merge_intervals`, since interval endpoints can be $\\pm\\infty$ - either explicitly, if the data type supports infinity, or implicitly by simply omitting the respective interval endpoint from the function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def east_west(n_rows_left: int = 5_000_000, n_rows_right: int = 5_000_000, seed: int = 42):\n",
    "    # taken from https://github.com/pola-rs/polars/blob/main/py-polars/tests/benchmark/test_join_where.py\n",
    "    \n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Generate two separate datasets where revenue/cost are linearly related to\n",
    "    # duration/time, but add some noise to the west table so that there are some\n",
    "    # rows where the cost for the same or greater time will be less than the east table.\n",
    "    east_dur = rng.integers(1_000, 10_000_000, n_rows_left)\n",
    "    east_rev = (east_dur * 0.123).astype(np.int32)\n",
    "    west_time = rng.integers(1_000, 500_000, n_rows_right)\n",
    "    west_cost = west_time * 0.123\n",
    "    west_cost += rng.normal(0.0, 1.0, n_rows_right)\n",
    "    west_cost = west_cost.astype(np.int32)\n",
    "\n",
    "    east = pd.DataFrame(\n",
    "        {\n",
    "            \"id\": np.arange(0, n_rows_left),\n",
    "            \"dur\": east_dur,\n",
    "            \"rev\": east_rev,\n",
    "            \"cores\": rng.integers(1, 10, n_rows_left),\n",
    "        }\n",
    "    )\n",
    "    west = pd.DataFrame(\n",
    "        {\n",
    "            \"t_id\": np.arange(0, n_rows_right),\n",
    "            \"time\": west_time,\n",
    "            \"cost\": west_cost,\n",
    "            \"cores\": rng.integers(1, 10, n_rows_right),\n",
    "        }\n",
    "    )\n",
    "    return east, west"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "east, west = east_west(50_000, 5000)\n",
    "print(len(east))\n",
    "print(len(west))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`catabra_pandas.merge_intervals`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size: 6381653\n",
      "wall time:   167.26 ms\n",
      "peak memory: 46827.27 MiB\n",
      "increment:   670.46 MiB\n"
     ]
    }
   ],
   "source": [
    "out, wall, peak, incr = profile(\n",
    "    catabra_pandas.merge_intervals,\n",
    "    [east, west],\n",
    "    dict(how=\"inner\", left_start=\"dur\", left_stop=\"dur\", right_stop=\"time\", include_right_stop=False, keep_order=False, copy=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`janitor.conditional_join`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size: 6381653\n",
      "wall time:   84.79 ms\n",
      "peak memory: 46686.77 MiB\n",
      "increment:   682.80 MiB\n"
     ]
    }
   ],
   "source": [
    "out_janitor, wall_janitor, peak_janitor, incr_janitor = profile(\n",
    "    janitor.conditional_join,\n",
    "    [east, west, (\"dur\", \"time\", \"<\")],\n",
    "    {}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**janitor is very fast, with comparable memory increment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pl.join_where`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "east_pl = pl.from_pandas(east)\n",
    "west_pl = pl.from_pandas(west)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size: 6381653\n",
      "wall time:   34.56 ms\n",
      "peak memory: 2449.11 MiB\n",
      "increment:   157.16 MiB\n"
     ]
    }
   ],
   "source": [
    "out_pl, wall_pl, peak_pl, incr_pl = profile(\n",
    "    east_pl.join_where,\n",
    "    [west_pl, pl.col(\"dur\") < pl.col(\"time\")],\n",
    "    {}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Polars is super fast, with negligible memory increment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`catabra_pandas.merge_intervals` is a fast alternative to both `janitor.conditional_join` and `polars.join_where`. Our experiments reveal that the time- and memory gains can be significant, especially if the **involved DataFrames are big (>1M rows)** and **both equality and inequality constraints are present**.\n",
    "\n",
    "The main downside of `catabra_pandas.merge_intervals` is that it can only handle interval overlap and -containment, and therefore covers only a subset of all possible inequality constraints. In real-world applications, this is often sufficient, though. Furthermore, every combination of inequalities can be represented as an equivalent combination of interval overlaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: A Few Words on `pd.IntervalIndex`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `IntervalIndex` is useful for working with interval data. If `df` has an `IntervalIndex`, then `df.loc[scalar]` returns\n",
    "    all rows whose index contains `scalar`.\n",
    "* `IntervalIndex` can be combined with other indexes in a `MultiIndex`. `df.loc[(i1, i2)]` selects rows based on both\n",
    "    indexes. **BUT SEE CAVEATS BELOW!**\n",
    "* `IntervalIndex` may contain overlapping intervals. In that case, `df.loc[scalar]` may return a `DataFrame` with multiple\n",
    "    rows (just as when used with other, non-unique indexes).\n",
    "* `IntervalIndex` allows `.loc`-indexing with lists of indices, e.g., `df.loc[[scalar1, scalar2, scalar3]]`. All matching\n",
    "    rows are returned, as expected.\n",
    "* Joining on `IntervalIndex` does *not* work as expected, neither `IntervalIndex` on `IntervalIndex`, nor `IntervalIndex` on\n",
    "    scalar index. If `IntervalIndex` is joined on `IntervalIndex`, only identical intervals are joined.\n",
    "* `IntervalIndex.overlaps` is only implemented for single intervals, not for other `IntervalIndex`.\n",
    "* It seems that `IntervalIndex`-`MultiIndex` combos [have not been thorougly integrated into pandas yet](https://github.com/pandas-dev/pandas/issues/25298), but only work\n",
    "\"occasionally\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING!** Combining `IntervalIndex`, `MultiIndex` and lists of indices does *not* give the expected result, namely only *one*\n",
    "row for each passed index. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3]  0    0\n",
       "        1    1\n",
       "[1, 6]  0    2\n",
       "        1    3\n",
       "dtype: int32"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(\n",
    "    index=pd.MultiIndex.from_product(\n",
    "        [pd.IntervalIndex.from_arrays([0, 1], [3, 6], closed='both'), pd.RangeIndex(2)]\n",
    "    ),\n",
    "    data=np.arange(4)\n",
    ")\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3]  1    1\n",
       "[1, 6]  1    3\n",
       "dtype: int32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.loc[(2.5, 1)]    # expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3]  1    1\n",
       "dtype: int32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.loc[[(2.5, 1)]]  # unexpected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The above behavior is independent of the order of `IntervalIndex` and `RangeIndex` within the `MultiIndex`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_dl_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
